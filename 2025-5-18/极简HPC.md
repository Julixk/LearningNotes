# HPC

## 超算 Supercomputer

服务节点 --> 超算集群

1. 体系结构

- 专用CPU：核心，线程数量
- NUMA架构
- ECC内存
- 专用主板：多GPU
2. 高性能网络
3. 电费高昂
 ......

## 基本工具

### SSH

安全外壳协议SSH

1. 基本用法：
ssh [username]@[hostname]

2. 非对称加密：RSA

3. 创建公钥私钥：ssh-keygen

4. 将本地公钥和私钥上传到服务器：
- 方法一：ssh-copy-id -i ~/.ssh/id_rsa.pub dl1
- cat ~/.ssh/id_rsa.pub | ssh dl1 'cat>>~/.ssh/authorized_keys'

### RSYNC

基本用法：
rsync [options] source destination
- rsync A B
- rsync -r A B         :递归同步
- rsync -a A B	       :递归同步的同时同步元信息 
- rsync --delete A B   :同步过程删除只存在B，不存在A的内容
（A和B都可以是远程地址）

## 开发工具

### SISD

一个指令，一个任务

### SIMD

一个指令，多个任务（存在限制）

--> 高速的计算方法

--> 开发复杂度高
--> 专用CPU组件

### SIMT

一个指令，不同硬件，取址不同

GPU

#### CUDA 
NVIDIA推出的集成技术，GPGPU的正式名称

#### ROCm
AMD推出的软件栈，用于GPU编程

#### OPENCL
OpenCL：为异构平台编写程序的框架，可由CPU,GPU,DSP,FPGA等加速器组成

1. 优势：
- 基于C/C++
- 跨平台

2. 与CUDA相比的劣势
- CUDA编译器更成熟
- CUDA的库更丰富
- CUDA社区和使用群体优势

### MULTI-THREAD:OpenMP
OpenMP是一套支持跨平台共享内存方式的多线程并发的编程API
为了利用多线程，我们可以使用一些更底层的库进行开发
（如Linux下可以使用pthread）
OpenMP提供了一种更统一且简洁且跨平台的方式进行开发

比如：
- #pragma omp for
- 实现了并行

##性能调优

### CPU缓存
CPU 通过将数据缓存到 L1/L2/L3 Cache 中，避免对内存的频繁访问造成的低效。

#### 局部性原理
##### 时间局部性
一个位置被引用，这个位置可能短时间内被多次引用。

##### 空间局部性
一个位置被引用，附近的位置也会被引用。

#### 优化方法
##### 循环展开
通过增加每次循环执行的操作数量，减少循环控制相关的开销，提高指令执行效率，更好地利用 CPU 缓存。

##### 内存预取
提前将后续可能会访问到的数据从内存加载到缓存中，当真正需要访问这些数据时，就能直接从缓存获取，减少等待数据从内存传输的时间。

##### ...  

### CPU流水线
CPU 本身是一个流水线结构，执行每一条指令分为多个阶段，流水线地执行。

在出现分支的地方可能导致流水线无法正常被填充。

#### 优化方法：分支预测
通过对程序中分支指令的走向进行预测，让 CPU 提前准备好可能要执行的指令，避免因分支导致流水线停顿，提高 CPU 执行指令的效率。 

### GPU
CUAD开发注意问题：
- 线程束分化
- GPU内存模型
- 并发
- ...

### PDMA：远程直接内存访问
绕过远程主机操作系统内核，访问其内存数据
节省CPU资源，提高系统吞吐量、降低网络延迟
