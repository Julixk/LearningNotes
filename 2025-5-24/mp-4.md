# MPI 并行编程技术 - 组通信概述

> 视频链接：[https://www.bilibili.com/video/BV15T4y1v7cb](https://www.bilibili.com/video/BV15T4y1v7cb)

## 一、什么是组通信（Collective Communication）

组通信是 MPI 中的一种通信方式，涉及一组进程之间的数据交换操作。与点对点通信不同，组通信要求通信组内的所有进程都参与操作，常用于数据的广播、收集、分发、规约等场景。

### 特点：

* 所有进程必须调用相同的组通信函数。
* 通信操作是同步的，通常会阻塞直到所有进程都达到通信点。
* 提供了高效的数据交换机制，适用于并行计算中的常见模式。

## 二、常用的组通信函数

### 1. 广播（Broadcast）

* **函数**：`MPI_Bcast`
* **作用**：将一个进程中的数据广播到通信组内的所有进程。
* **应用场景**：初始化数据分发，配置参数同步等。

### 2. 收集（Gather）

* **函数**：`MPI_Gather`
* **作用**：将通信组内各个进程的数据收集到指定的根进程。
* **应用场景**：结果汇总，数据聚合等。

### 3. 分发（Scatter）

* **函数**：`MPI_Scatter`
* **作用**：将根进程的数据分发到通信组内的各个进程。
* **应用场景**：任务分配，数据分片等。

### 4. 全收集（Allgather）

* **函数**：`MPI_Allgather`
* **作用**：将各个进程的数据收集并分发到所有进程。
* **应用场景**：数据同步，状态共享等。

### 5. 归约（Reduce）

* **函数**：`MPI_Reduce`
* **作用**：对通信组内各个进程的数据进行规约操作，并将结果返回给根进程。
* **常用操作**：求和（`MPI_SUM`）、最大值（`MPI_MAX`）、最小值（`MPI_MIN`）等。
* **应用场景**：统计计算，结果合并等。

### 6. 全归约（Allreduce）

* **函数**：`MPI_Allreduce`
* **作用**：对通信组内各个进程的数据进行规约操作，并将结果分发到所有进程。
* **应用场景**：全局统计，状态同步等。

### 7. 归约分发（Reduce\_scatter）

* **函数**：`MPI_Reduce_scatter`
* **作用**：结合归约和分发操作，将规约结果分发到各个进程。
* **应用场景**：并行计算中的负载均衡等。

### 8. 前缀和（Scan）

* **函数**：`MPI_Scan`
* **作用**：对通信组内的进程进行前缀规约操作。
* **应用场景**：并行前缀计算，累计操作等。

### 9. 全互换（Alltoall）

* **函数**：`MPI_Alltoall`
* **作用**：通信组内的每个进程向其他所有进程发送不同的数据。
* **应用场景**：矩阵转置，全连接通信等。

### 10. 屏障同步（Barrier）

* **函数**：`MPI_Barrier`
* **作用**：使通信组内的所有进程同步，等待所有进程都达到屏障点后再继续执行。
* **应用场景**：阶段同步，调试等。

## 三、组通信的注意事项

* 所有参与通信的进程必须调用相同的组通信函数，否则可能导致程序死锁或错误。
* 数据类型和数据量必须在所有进程中保持一致。
* 组通信函数通常是阻塞的，直到通信完成后才返回。

## 四、示例代码

以下是一个使用 `MPI_Bcast` 进行广播操作的示例：

```c
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    int rank, size;
    int data;

    MPI_Init(&argc, &argv); // 初始化MPI环境
    MPI_Comm_rank(MPI_COMM_WORLD, &rank); // 获取当前进程编号
    MPI_Comm_size(MPI_COMM_WORLD, &size); // 获取总进程数

    if (rank == 0) {
        data = 100; // 初始化数据
    }

    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD); // 广播数据

    printf("Process %d received data %d\n", rank, data);

    MPI_Finalize(); // 结束MPI环境
    return 0;
}
```

